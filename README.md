# FSIRC
Feature selection is usually used as a preprocessing step for outlier detection to obtain significant performance. There is little work on feature selection for outlier detection in categorical data, and many studies do not consider the interaction and complementarity of features simultaneously, or even confuse them. In this paper, we first design criteria to measure the feature complementarity and redundancy based on the feature weight gain, and then propose a new feature selection method for outlier detection in categorical data which takes into account the feature relevance, interaction, redundancy and complementarity. The proposed method can find potential complementary features for the selected feature subset containing as much positive information as possible and remove redundant features without beneficial information. Extension evaluation results on 14 real-world datasets demonstrate that the proposed method acquires an average 77% dimensionality reduction rate and enables three distinct types of outlier detection methods to obtain superior AUC than that on the original dataset. Our method performs best in all outlier detectors on average compared with the other five state-of-the-art feature selection methods.

[1] Wang, L., & Ke, Y. (2023). Feature selection considering interaction, redundancy and complementarity for outlier detection in categorical data. Knowledge-Based Systems, 110678.
[2] Pang, G., Cao, L., Chen, L., & Liu, H. (2016, December). Unsupervised feature selection for outlier detection by modelling hierarchical value-feature couplings. In 2016 IEEE 16th International Conference on Data Mining (ICDM) (pp. 410-419). IEEE.
